model: .cache/modelscope/models/Qwen/Qwen3-VL-4B-Instruct
host: "127.0.0.1"
port: 8000
uvicorn-log-level: "info"
dtype: "float16"
tensor-parallel-size: 4
max-model-len: 4096
max_num_seqs: 128
gpu_memory_utilization: 0.8
served-model-name: "Qwen3-VL-4B-Instruct"